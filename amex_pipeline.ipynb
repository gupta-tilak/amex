{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed540d6a",
   "metadata": {},
   "source": [
    "# Amex Pipeline: Staged Execution\n",
    "This notebook allows you to run the Amex pipeline in stages: data loading, cleaning, feature engineering, EDA, feature selection, model training, validation, and submission generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d05a78f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data.data_loader import load_all_data\n",
    "from data.data_cleaning import clean_all_data_advanced\n",
    "from data.advanced_feature_engineering import create_full_feature_set_advanced\n",
    "from eda.exploratory_analysis import (\n",
    "    plot_target_distribution, plot_missing_values, plot_feature_distributions, \n",
    "    plot_correlation_heatmap, plot_new_feature_analysis\n",
    ")\n",
    "from utils.metrics import map7_from_dataframe\n",
    "from utils.submission import generate_submission\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def validate_pipeline_data(data, stage_name):\n",
    "    \"\"\"Validate data at each pipeline stage\"\"\"\n",
    "    print(f\"\\n=== {stage_name} Validation ===\")\n",
    "    print(f\"Shape: {data.shape}\")\n",
    "    \n",
    "    # Check for NaN values\n",
    "    nan_count = data.isna().sum().sum()\n",
    "    print(f\"NaN values: {nan_count}\")\n",
    "    \n",
    "    # Check for infinite values\n",
    "    numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "    inf_count = np.isinf(data[numeric_cols]).sum().sum()\n",
    "    print(f\"Infinite values: {inf_count}\")\n",
    "    \n",
    "    # Memory usage\n",
    "    memory_mb = data.memory_usage(deep=True).sum() / 1024 / 1024\n",
    "    print(f\"Memory usage: {memory_mb:.1f} MB\")\n",
    "    \n",
    "    if nan_count > 0 or inf_count > 0:\n",
    "        print(\"⚠️  Data quality issues detected!\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"✅ Data validation passed\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1a46ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STAGE 1: DATA LOADING ===\n",
      "✅ Data loaded successfully\n",
      "Train shape: (770164, 372)\n",
      "Test shape: (369301, 371)\n",
      "\n",
      "=== Raw Train Data Validation ===\n",
      "Shape: (770164, 372)\n",
      "NaN values: 68296406\n",
      "Infinite values: 0\n",
      "Memory usage: 1084.8 MB\n",
      "⚠️  Data quality issues detected!\n"
     ]
    }
   ],
   "source": [
    "# Stage 1: Load data with validation\n",
    "print(\"=== STAGE 1: DATA LOADING ===\")\n",
    "try:\n",
    "    data = load_all_data()\n",
    "    print(f\"✅ Data loaded successfully\")\n",
    "    print(f\"Train shape: {data['train'].shape}\")\n",
    "    print(f\"Test shape: {data['test'].shape}\")\n",
    "    \n",
    "    # Validate loaded data\n",
    "    validate_pipeline_data(data['train'], \"Raw Train Data\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Data loading failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e418c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STAGE 2: ADVANCED DATA CLEANING ===\n",
      "Starting robust advanced data cleaning pipeline...\n",
      "Starting robust advanced data cleaning...\n",
      "Removed 0 duplicate rows\n",
      "Creating customer behavioral features...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== STAGE 2: ADVANCED DATA CLEANING ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     cleaned_data = \u001b[43mclean_all_data_advanced\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✅ Advanced cleaning completed\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCleaned train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcleaned_data[\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m].shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/data/data_cleaning.py:518\u001b[39m, in \u001b[36mclean_all_data_advanced\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    515\u001b[39m offer_metadata_clean = clean_offer_metadata(data.get(\u001b[33m'\u001b[39m\u001b[33moffer_metadata\u001b[39m\u001b[33m'\u001b[39m, pd.DataFrame()))\n\u001b[32m    517\u001b[39m \u001b[38;5;66;03m# Robust advanced cleaning for train data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m518\u001b[39m train_clean, kmeans_model, scaler, clustering_features = \u001b[43mclean_train_data_advanced_robust\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_event_clean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_trans_clean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffer_metadata_clean\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[38;5;66;03m# Clean test data using the same robust strategy\u001b[39;00m\n\u001b[32m    523\u001b[39m test_clean, _, _, _ = clean_train_data_advanced_robust(\n\u001b[32m    524\u001b[39m     data[\u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m], add_event_clean, add_trans_clean, offer_metadata_clean\n\u001b[32m    525\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/data/data_cleaning.py:395\u001b[39m, in \u001b[36mclean_train_data_advanced_robust\u001b[39m\u001b[34m(df, add_event, add_trans, offer_metadata)\u001b[39m\n\u001b[32m    392\u001b[39m df[object_cols] = df[object_cols].fillna(\u001b[33m'\u001b[39m\u001b[33mUnknown\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    394\u001b[39m \u001b[38;5;66;03m# Create behavioral features with error handling\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m customer_event_features, customer_trans_features, offer_features = \u001b[43mcreate_customer_behavioral_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_event\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_trans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffer_metadata\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[38;5;66;03m# Create customer segments with robust clustering\u001b[39;00m\n\u001b[32m    400\u001b[39m enriched_data, kmeans_model, scaler, clustering_features = create_customer_segments_robust(\n\u001b[32m    401\u001b[39m     df, customer_event_features, customer_trans_features\n\u001b[32m    402\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/data/data_cleaning.py:65\u001b[39m, in \u001b[36mcreate_customer_behavioral_features\u001b[39m\u001b[34m(train_data, add_event, add_trans, offer_metadata)\u001b[39m\n\u001b[32m     62\u001b[39m customer_event_features = pd.DataFrame({\u001b[33m'\u001b[39m\u001b[33mid2\u001b[39m\u001b[33m'\u001b[39m: train_data[\u001b[33m'\u001b[39m\u001b[33mid2\u001b[39m\u001b[33m'\u001b[39m].unique()})\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m add_event.empty \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mid2\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m add_event.columns:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     event_aggs = \u001b[43madd_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid3\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_aggregation\u001b[49m\u001b[43m(\u001b[49m\u001b[43madd_event\u001b[49m\u001b[43m[\u001b[49m\u001b[43madd_event\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid3\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcount\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid4\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_aggregation\u001b[49m\u001b[43m(\u001b[49m\u001b[43madd_event\u001b[49m\u001b[43m[\u001b[49m\u001b[43madd_event\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid4\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcount\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m.reset_index()\n\u001b[32m     70\u001b[39m     event_aggs.columns = [\u001b[33m'\u001b[39m\u001b[33mid2\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mevent_count\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mevent_diversity\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     71\u001b[39m     customer_event_features = customer_event_features.merge(event_aggs, on=\u001b[33m'\u001b[39m\u001b[33mid2\u001b[39m\u001b[33m'\u001b[39m, how=\u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/venv/lib/python3.11/site-packages/pandas/core/groupby/generic.py:1432\u001b[39m, in \u001b[36mDataFrameGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m   1429\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = engine_kwargs\n\u001b[32m   1431\u001b[39m op = GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args=args, kwargs=kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1432\u001b[39m result = \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1433\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1434\u001b[39m     \u001b[38;5;66;03m# GH #52849\u001b[39;00m\n\u001b[32m   1435\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.as_index \u001b[38;5;129;01mand\u001b[39;00m is_list_like(func):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/venv/lib/python3.11/site-packages/pandas/core/apply.py:190\u001b[39m, in \u001b[36mApply.agg\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_str()\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(func):\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magg_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[32m    192\u001b[39m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agg_list_like()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/venv/lib/python3.11/site-packages/pandas/core/apply.py:423\u001b[39m, in \u001b[36mApply.agg_dict_like\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34magg_dict_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> DataFrame | Series:\n\u001b[32m    416\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    417\u001b[39m \u001b[33;03m    Compute aggregation in the case of a dict-like argument.\u001b[39;00m\n\u001b[32m    418\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    421\u001b[39m \u001b[33;03m    Result of aggregation.\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43magg_or_apply_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43magg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/venv/lib/python3.11/site-packages/pandas/core/apply.py:1603\u001b[39m, in \u001b[36mGroupByApply.agg_or_apply_dict_like\u001b[39m\u001b[34m(self, op_name)\u001b[39m\n\u001b[32m   1598\u001b[39m     kwargs.update({\u001b[33m\"\u001b[39m\u001b[33mengine\u001b[39m\u001b[33m\"\u001b[39m: engine, \u001b[33m\"\u001b[39m\u001b[33mengine_kwargs\u001b[39m\u001b[33m\"\u001b[39m: engine_kwargs})\n\u001b[32m   1600\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m com.temp_setattr(\n\u001b[32m   1601\u001b[39m     obj, \u001b[33m\"\u001b[39m\u001b[33mas_index\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, condition=\u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[33m\"\u001b[39m\u001b[33mas_index\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1602\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1603\u001b[39m     result_index, result_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_dict_like\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1605\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1606\u001b[39m result = \u001b[38;5;28mself\u001b[39m.wrap_results_dict_like(selected_obj, result_index, result_data)\n\u001b[32m   1607\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/venv/lib/python3.11/site-packages/pandas/core/apply.py:496\u001b[39m, in \u001b[36mApply.compute_dict_like\u001b[39m\u001b[34m(self, op_name, selected_obj, selection, kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m         results += key_data\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    495\u001b[39m     \u001b[38;5;66;03m# key used for column selection and output\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     results = \u001b[43m[\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gotitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    500\u001b[39m     keys = \u001b[38;5;28mlist\u001b[39m(func.keys())\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m keys, results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/venv/lib/python3.11/site-packages/pandas/core/apply.py:497\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    493\u001b[39m         results += key_data\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    495\u001b[39m     \u001b[38;5;66;03m# key used for column selection and output\u001b[39;00m\n\u001b[32m    496\u001b[39m     results = [\n\u001b[32m--> \u001b[39m\u001b[32m497\u001b[39m         \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gotitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    498\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m func.items()\n\u001b[32m    499\u001b[39m     ]\n\u001b[32m    500\u001b[39m     keys = \u001b[38;5;28mlist\u001b[39m(func.keys())\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m keys, results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/venv/lib/python3.11/site-packages/pandas/core/groupby/generic.py:294\u001b[39m, in \u001b[36mSeriesGroupBy.aggregate\u001b[39m\u001b[34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    291\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._python_agg_general(func, *args, **kwargs)\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_python_agg_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m    296\u001b[39m     \u001b[38;5;66;03m# KeyError raised in test_groupby.test_basic is bc the func does\u001b[39;00m\n\u001b[32m    297\u001b[39m     \u001b[38;5;66;03m#  a dictionary lookup on group.name, but group name is not\u001b[39;00m\n\u001b[32m    298\u001b[39m     \u001b[38;5;66;03m#  pinned in _python_agg_general, only in _aggregate_named\u001b[39;00m\n\u001b[32m    299\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._aggregate_named(func, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/venv/lib/python3.11/site-packages/pandas/core/groupby/generic.py:327\u001b[39m, in \u001b[36mSeriesGroupBy._python_agg_general\u001b[39m\u001b[34m(self, func, *args, **kwargs)\u001b[39m\n\u001b[32m    324\u001b[39m f = \u001b[38;5;28;01mlambda\u001b[39;00m x: func(x, *args, **kwargs)\n\u001b[32m    326\u001b[39m obj = \u001b[38;5;28mself\u001b[39m._obj_with_exclusions\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_grouper\u001b[49m\u001b[43m.\u001b[49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m res = obj._constructor(result, name=obj.name)\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wrap_aggregated_output(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/venv/lib/python3.11/site-packages/pandas/core/groupby/ops.py:864\u001b[39m, in \u001b[36mBaseGrouper.agg_series\u001b[39m\u001b[34m(self, obj, func, preserve_dtype)\u001b[39m\n\u001b[32m    857\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj._values, np.ndarray):\n\u001b[32m    858\u001b[39m     \u001b[38;5;66;03m# we can preserve a little bit more aggressively with EA dtype\u001b[39;00m\n\u001b[32m    859\u001b[39m     \u001b[38;5;66;03m#  because maybe_cast_pointwise_result will do a try/except\u001b[39;00m\n\u001b[32m    860\u001b[39m     \u001b[38;5;66;03m#  with _from_sequence.  NB we are assuming here that _from_sequence\u001b[39;00m\n\u001b[32m    861\u001b[39m     \u001b[38;5;66;03m#  is sufficiently strict that it casts appropriately.\u001b[39;00m\n\u001b[32m    862\u001b[39m     preserve_dtype = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m864\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    866\u001b[39m npvalues = lib.maybe_convert_objects(result, try_float=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    867\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m preserve_dtype:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/venv/lib/python3.11/site-packages/pandas/core/groupby/ops.py:885\u001b[39m, in \u001b[36mBaseGrouper._aggregate_series_pure_python\u001b[39m\u001b[34m(self, obj, func)\u001b[39m\n\u001b[32m    882\u001b[39m splitter = \u001b[38;5;28mself\u001b[39m._get_splitter(obj, axis=\u001b[32m0\u001b[39m)\n\u001b[32m    884\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[32m--> \u001b[39m\u001b[32m885\u001b[39m     res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    886\u001b[39m     res = extract_result(res)\n\u001b[32m    888\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initialized:\n\u001b[32m    889\u001b[39m         \u001b[38;5;66;03m# We only do this validation on the first iteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/venv/lib/python3.11/site-packages/pandas/core/groupby/generic.py:324\u001b[39m, in \u001b[36mSeriesGroupBy._python_agg_general.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    322\u001b[39m     alias = com._builtin_table_alias[func]\n\u001b[32m    323\u001b[39m     warn_alias_replacement(\u001b[38;5;28mself\u001b[39m, orig_func, alias)\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m f = \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m obj = \u001b[38;5;28mself\u001b[39m._obj_with_exclusions\n\u001b[32m    327\u001b[39m result = \u001b[38;5;28mself\u001b[39m._grouper.agg_series(obj, f)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/data/data_cleaning.py:66\u001b[39m, in \u001b[36mcreate_customer_behavioral_features.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m     62\u001b[39m customer_event_features = pd.DataFrame({\u001b[33m'\u001b[39m\u001b[33mid2\u001b[39m\u001b[33m'\u001b[39m: train_data[\u001b[33m'\u001b[39m\u001b[33mid2\u001b[39m\u001b[33m'\u001b[39m].unique()})\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m add_event.empty \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mid2\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m add_event.columns:\n\u001b[32m     65\u001b[39m     event_aggs = add_event.groupby(\u001b[33m'\u001b[39m\u001b[33mid2\u001b[39m\u001b[33m'\u001b[39m).agg({\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mid3\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: safe_aggregation(add_event[\u001b[43madd_event\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m], \u001b[33m'\u001b[39m\u001b[33mid3\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcount\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     67\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mid4\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: safe_aggregation(add_event[add_event[\u001b[33m'\u001b[39m\u001b[33mid2\u001b[39m\u001b[33m'\u001b[39m].isin([x.name])], \u001b[33m'\u001b[39m\u001b[33mid4\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcount\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     68\u001b[39m     }).reset_index()\n\u001b[32m     70\u001b[39m     event_aggs.columns = [\u001b[33m'\u001b[39m\u001b[33mid2\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mevent_count\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mevent_diversity\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     71\u001b[39m     customer_event_features = customer_event_features.merge(event_aggs, on=\u001b[33m'\u001b[39m\u001b[33mid2\u001b[39m\u001b[33m'\u001b[39m, how=\u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/venv/lib/python3.11/site-packages/pandas/core/series.py:5570\u001b[39m, in \u001b[36mSeries.isin\u001b[39m\u001b[34m(self, values)\u001b[39m\n\u001b[32m   5497\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34misin\u001b[39m(\u001b[38;5;28mself\u001b[39m, values) -> Series:\n\u001b[32m   5498\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5499\u001b[39m \u001b[33;03m    Whether elements in Series are contained in `values`.\u001b[39;00m\n\u001b[32m   5500\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5568\u001b[39m \u001b[33;03m    dtype: bool\u001b[39;00m\n\u001b[32m   5569\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5570\u001b[39m     result = \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5571\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._constructor(result, index=\u001b[38;5;28mself\u001b[39m.index, copy=\u001b[38;5;28;01mFalse\u001b[39;00m).__finalize__(\n\u001b[32m   5572\u001b[39m         \u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33misin\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   5573\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/venv/lib/python3.11/site-packages/pandas/core/algorithms.py:505\u001b[39m, in \u001b[36misin\u001b[39m\u001b[34m(comps, values)\u001b[39m\n\u001b[32m    502\u001b[39m comps_array = extract_array(comps_array, extract_numpy=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(comps_array, np.ndarray):\n\u001b[32m    504\u001b[39m     \u001b[38;5;66;03m# i.e. Extension Array\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomps_array\u001b[49m\u001b[43m.\u001b[49m\u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(comps_array.dtype):\n\u001b[32m    508\u001b[39m     \u001b[38;5;66;03m# Dispatch to DatetimeLikeArrayMixin.isin\u001b[39;00m\n\u001b[32m    509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pd_array(comps_array).isin(values)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/venv/lib/python3.11/site-packages/pandas/core/arrays/string_.py:812\u001b[39m, in \u001b[36mStringArray.isin\u001b[39m\u001b[34m(self, values)\u001b[39m\n\u001b[32m    808\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m np.zeros(\u001b[38;5;28mself\u001b[39m.shape, dtype=\u001b[38;5;28mbool\u001b[39m)\n\u001b[32m    810\u001b[39m     values = \u001b[38;5;28mself\u001b[39m._from_sequence(values, dtype=\u001b[38;5;28mself\u001b[39m.dtype)\n\u001b[32m--> \u001b[39m\u001b[32m812\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43misin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/venv/lib/python3.11/site-packages/pandas/core/algorithms.py:545\u001b[39m, in \u001b[36misin\u001b[39m\u001b[34m(comps, values)\u001b[39m\n\u001b[32m    542\u001b[39m     comps_array = comps_array.astype(common, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    543\u001b[39m     f = htable.ismember\n\u001b[32m--> \u001b[39m\u001b[32m545\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomps_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Stage 2: Advanced cleaning with comprehensive error handling\n",
    "print(\"\\n=== STAGE 2: ADVANCED DATA CLEANING ===\")\n",
    "try:\n",
    "    cleaned_data = clean_all_data_advanced(data)\n",
    "    print(f\"✅ Advanced cleaning completed\")\n",
    "    print(f\"Cleaned train shape: {cleaned_data['train'].shape}\")\n",
    "    \n",
    "    # Validate cleaned data\n",
    "    is_valid = validate_pipeline_data(cleaned_data['train'], \"Cleaned Train Data\")\n",
    "    \n",
    "    if not is_valid:\n",
    "        print(\"⚠️  Performing emergency data cleanup...\")\n",
    "        # Emergency cleanup\n",
    "        numeric_cols = cleaned_data['train'].select_dtypes(include=[np.number]).columns\n",
    "        cleaned_data['train'][numeric_cols] = cleaned_data['train'][numeric_cols].fillna(0)\n",
    "        cleaned_data['train'][numeric_cols] = cleaned_data['train'][numeric_cols].replace([np.inf, -np.inf], 0)\n",
    "        \n",
    "        cleaned_data['test'][numeric_cols] = cleaned_data['test'][numeric_cols].fillna(0)\n",
    "        cleaned_data['test'][numeric_cols] = cleaned_data['test'][numeric_cols].replace([np.inf, -np.inf], 0)\n",
    "        \n",
    "        print(\"✅ Emergency cleanup completed\")\n",
    "        validate_pipeline_data(cleaned_data['train'], \"Emergency Cleaned Data\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Data cleaning failed: {e}\")\n",
    "    print(\"Falling back to basic cleaning...\")\n",
    "    \n",
    "    # Emergency fallback\n",
    "    cleaned_data = {\n",
    "        'train': data['train'].fillna(0),\n",
    "        'test': data['test'].fillna(0)\n",
    "    }\n",
    "    print(\"✅ Basic cleaning completed as fallback\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9247b0af",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'isna'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcleaned_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43misna\u001b[49m().sum().sum()  \u001b[38;5;66;03m# Check for any remaining NaNs\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'dict' object has no attribute 'isna'"
     ]
    }
   ],
   "source": [
    "# Stage 3: Advanced feature engineering with robust error handling\n",
    "print(\"\\n=== STAGE 3: ADVANCED FEATURE ENGINEERING ===\")\n",
    "try:\n",
    "    # Validate input data before feature engineering\n",
    "    print(\"Validating input data...\")\n",
    "    input_valid = validate_pipeline_data(cleaned_data['train'], \"Pre-Feature Engineering\")\n",
    "    \n",
    "    if not input_valid:\n",
    "        print(\"⚠️  Input data has issues, performing pre-processing cleanup...\")\n",
    "        numeric_cols = cleaned_data['train'].select_dtypes(include=[np.number]).columns\n",
    "        cleaned_data['train'][numeric_cols] = cleaned_data['train'][numeric_cols].fillna(0)\n",
    "        cleaned_data['train'][numeric_cols] = cleaned_data['train'][numeric_cols].replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    print(\"Starting feature engineering...\")\n",
    "    train_engineered, selected_features = create_full_feature_set_advanced(cleaned_data['train'])\n",
    "    test_engineered, _ = create_full_feature_set_advanced(cleaned_data['test'])\n",
    "    \n",
    "    print(f\"✅ Feature engineering completed\")\n",
    "    print(f\"Final train shape: {train_engineered.shape}\")\n",
    "    print(f\"Selected features: {len(selected_features)}\")\n",
    "    \n",
    "    validate_pipeline_data(train_engineered, \"Engineered Train Data\")\n",
    "    \n",
    "    print(\"\\n=== Feature Engineering Quality Report ===\")\n",
    "    numeric_cols = train_engineered.select_dtypes(include=[np.number]).columns\n",
    "    missing_indicator_count = (train_engineered[numeric_cols] == -999).sum().sum()\n",
    "    print(f\"Remaining -999 values: {missing_indicator_count}\")\n",
    "    print(f\"Data types: {train_engineered.dtypes.value_counts().to_dict()}\")\n",
    "    \n",
    "    if selected_features:\n",
    "        print(f\"\\nTop 10 selected features:\")\n",
    "        for i, feature in enumerate(selected_features[:10]):\n",
    "            print(f\"{i+1:2d}. {feature}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Feature engineering failed: {e}\")\n",
    "    print(\"Using original cleaned data without advanced features...\")\n",
    "    \n",
    "    train_engineered = cleaned_data['train'].copy()\n",
    "    test_engineered = cleaned_data['test'].copy()\n",
    "    selected_features = [col for col in train_engineered.columns if col.startswith('f')][:50]\n",
    "    print(f\"✅ Using {len(selected_features)} basic features as fallback\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726b66d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing advanced feature engineering...\n",
      "Starting advanced feature engineering...\n",
      "Creating interaction features...\n",
      "Created 4 interaction features\n",
      "Creating temporal features...\n",
      "Created 4 temporal features\n",
      "Creating aggregated features...\n",
      "Created 12 aggregated features\n",
      "Performing feature selection...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Advanced feature engineering\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPerforming advanced feature engineering...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m train_engineered, selected_features = \u001b[43mcreate_full_feature_set_advanced\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcleaned_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m test_engineered, _ = create_full_feature_set_advanced(cleaned_data[\u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFinal train shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_engineered.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/data/advanced_feature_engineering.py:144\u001b[39m, in \u001b[36mcreate_full_feature_set_advanced\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m    141\u001b[39m df, aggregated_features = create_aggregated_features(df)\n\u001b[32m    143\u001b[39m \u001b[38;5;66;03m# Feature selection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m df, selected_features = \u001b[43mfeature_selection_by_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAdvanced feature engineering completed.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    147\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal features created: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(interaction_features\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39mtemporal_features\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39maggregated_features)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/data/advanced_feature_engineering.py:112\u001b[39m, in \u001b[36mfeature_selection_by_importance\u001b[39m\u001b[34m(df, target_col, top_k)\u001b[39m\n\u001b[32m    109\u001b[39m     X[col] = le.fit_transform(X[col].astype(\u001b[38;5;28mstr\u001b[39m))\n\u001b[32m    111\u001b[39m \u001b[38;5;66;03m# Calculate mutual information\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m mi_scores = \u001b[43mmutual_info_classif\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# Get top features\u001b[39;00m\n\u001b[32m    115\u001b[39m feature_importance = pd.DataFrame({\n\u001b[32m    116\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfeature\u001b[39m\u001b[33m'\u001b[39m: feature_cols,\n\u001b[32m    117\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mimportance\u001b[39m\u001b[33m'\u001b[39m: mi_scores\n\u001b[32m    118\u001b[39m }).sort_values(\u001b[33m'\u001b[39m\u001b[33mimportance\u001b[39m\u001b[33m'\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/venv/lib/python3.11/site-packages/sklearn/feature_selection/_mutual_info.py:571\u001b[39m, in \u001b[36mmutual_info_classif\u001b[39m\u001b[34m(X, y, discrete_features, n_neighbors, copy, random_state, n_jobs)\u001b[39m\n\u001b[32m    475\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Estimate mutual information for a discrete target variable.\u001b[39;00m\n\u001b[32m    476\u001b[39m \n\u001b[32m    477\u001b[39m \u001b[33;03mMutual information (MI) [1]_ between two random variables is a non-negative\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    568\u001b[39m \u001b[33;03m       0.   , 0.   , 0.   , 0.     , 0.])\u001b[39;00m\n\u001b[32m    569\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    570\u001b[39m check_classification_targets(y)\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_estimate_mi\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdiscrete_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdiscrete_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdiscrete_target\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/venv/lib/python3.11/site-packages/sklearn/feature_selection/_mutual_info.py:271\u001b[39m, in \u001b[36m_estimate_mi\u001b[39m\u001b[34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state, n_jobs)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_estimate_mi\u001b[39m(\n\u001b[32m    203\u001b[39m     X,\n\u001b[32m    204\u001b[39m     y,\n\u001b[32m   (...)\u001b[39m\u001b[32m    211\u001b[39m     n_jobs=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    212\u001b[39m ):\n\u001b[32m    213\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Estimate mutual information between the features and the target.\u001b[39;00m\n\u001b[32m    214\u001b[39m \n\u001b[32m    215\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    269\u001b[39m \u001b[33;03m           Data Sets\". PLoS ONE 9(2), 2014.\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m     X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdiscrete_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    272\u001b[39m     n_samples, n_features = X.shape\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(discrete_features, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1368\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1362\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1363\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires y to be passed, but the target y is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1364\u001b[39m     )\n\u001b[32m   1366\u001b[39m ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1385\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m   1387\u001b[39m check_consistent_length(X, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1105\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1099\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1100\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1101\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1102\u001b[39m     )\n\u001b[32m   1104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1114\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/amex/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:105\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_array_api \u001b[38;5;129;01mand\u001b[39;00m X.dtype == np.dtype(\u001b[33m\"\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _object_dtype_isnan(X).any():\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInput contains NaN\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# We need only consider float arrays, hence can early return for all else.\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m xp.isdtype(X.dtype, (\u001b[33m\"\u001b[39m\u001b[33mreal floating\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcomplex floating\u001b[39m\u001b[33m\"\u001b[39m)):\n",
      "\u001b[31mValueError\u001b[39m: Input contains NaN"
     ]
    }
   ],
   "source": [
    "# Stage 4: Final validation and summary\n",
    "print(\"\\n=== STAGE 4: FINAL VALIDATION ===\")\n",
    "\n",
    "def final_pipeline_validation(train_data, test_data, features):\n",
    "    \"\"\"Comprehensive validation before model training\"\"\"\n",
    "    print(\"Performing comprehensive pipeline validation...\")\n",
    "    \n",
    "    issues = []\n",
    "    \n",
    "    print(f\"Train data shape: {train_data.shape}\")\n",
    "    print(f\"Test data shape: {test_data.shape}\")\n",
    "    \n",
    "    if 'y' in train_data.columns:\n",
    "        target_dist = train_data['y'].value_counts()\n",
    "        print(f\"Target distribution: {target_dist.to_dict()}\")\n",
    "        if len(target_dist) < 2:\n",
    "            issues.append(\"Target variable has insufficient classes\")\n",
    "    else:\n",
    "        issues.append(\"Target variable 'y' not found\")\n",
    "    \n",
    "    available_features = [f for f in features if f in train_data.columns]\n",
    "    print(f\"Available features: {len(available_features)}/{len(features)}\")\n",
    "    \n",
    "    if len(available_features) < len(features) * 0.8:\n",
    "        issues.append(f\"Too many features missing: {len(features) - len(available_features)}\")\n",
    "    \n",
    "    train_nan = train_data.isna().sum().sum()\n",
    "    test_nan = test_data.isna().sum().sum()\n",
    "    \n",
    "    if train_nan > 0 or test_nan > 0:\n",
    "        issues.append(f\"NaN values found - Train: {train_nan}, Test: {test_nan}\")\n",
    "    \n",
    "    numeric_cols = train_data.select_dtypes(include=[np.number]).columns\n",
    "    train_inf = np.isinf(train_data[numeric_cols]).sum().sum()\n",
    "    test_inf = np.isinf(test_data[numeric_cols]).sum().sum()\n",
    "    \n",
    "    if train_inf > 0 or test_inf > 0:\n",
    "        issues.append(f\"Infinite values found - Train: {train_inf}, Test: {test_inf}\")\n",
    "    \n",
    "    if issues:\n",
    "        print(\"\\n⚠️  VALIDATION ISSUES DETECTED:\")\n",
    "        for i, issue in enumerate(issues, 1):\n",
    "            print(f\"{i}. {issue}\")\n",
    "        return False, available_features\n",
    "    else:\n",
    "        print(\"\\n✅ ALL VALIDATION CHECKS PASSED\")\n",
    "        return True, available_features\n",
    "\n",
    "validation_passed, final_features = final_pipeline_validation(\n",
    "    train_engineered, test_engineered, selected_features\n",
    ")\n",
    "\n",
    "if not validation_passed:\n",
    "    print(\"\\n🔧 APPLYING FINAL FIXES...\")\n",
    "    numeric_cols = train_engineered.select_dtypes(include=[np.number]).columns\n",
    "    train_engineered[numeric_cols] = train_engineered[numeric_cols].fillna(0).replace([np.inf, -np.inf], 0)\n",
    "    test_engineered[numeric_cols] = test_engineered[numeric_cols].fillna(0).replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    validation_passed, final_features = final_pipeline_validation(\n",
    "        train_engineered, test_engineered, selected_features\n",
    "    )\n",
    "\n",
    "print(f\"\\n=== PIPELINE SUMMARY ===\")\n",
    "print(f\"Status: {'✅ READY FOR MODEL TRAINING' if validation_passed else '❌ ISSUES REMAIN'}\")\n",
    "print(f\"Final train shape: {train_engineered.shape}\")\n",
    "print(f\"Final test shape: {test_engineered.shape}\")\n",
    "print(f\"Features for modeling: {len(final_features)}\")\n",
    "print(f\"Memory usage: {(train_engineered.memory_usage(deep=True).sum() / 1024 / 1024):.1f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0424aa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 5: Model Training (if validation passed)\n",
    "print(\"\\n=== STAGE 5: MODEL TRAINING ===\")\n",
    "\n",
    "if validation_passed and len(final_features) > 0:\n",
    "    try:\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from sklearn.metrics import roc_auc_score, classification_report\n",
    "        \n",
    "        X = train_engineered[final_features].copy()\n",
    "        y = train_engineered['y']\n",
    "        \n",
    "        categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "        if len(categorical_cols) > 0:\n",
    "            print(f\"Encoding {len(categorical_cols)} categorical features...\")\n",
    "            from sklearn.preprocessing import LabelEncoder\n",
    "            for col in categorical_cols:\n",
    "                le = LabelEncoder()\n",
    "                X[col] = le.fit_transform(X[col].astype(str))\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        print(f\"Training set: {X_train.shape}\")\n",
    "        print(f\"Validation set: {X_val.shape}\")\n",
    "        \n",
    "        print(\"Training Random Forest model...\")\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        val_pred = model.predict_proba(X_val)[:, 1]\n",
    "        auc_score = roc_auc_score(y_val, val_pred)\n",
    "        \n",
    "        print(f\"\\n✅ Model training completed!\")\n",
    "        print(f\"Validation AUC: {auc_score:.4f}\")\n",
    "        \n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': final_features,\n",
    "            'importance': model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        print(f\"\\nTop 10 most important features:\")\n",
    "        print(feature_importance.head(10))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Model training failed: {e}\")\n",
    "        print(\"Pipeline completed data preparation successfully, but model training needs debugging.\")\n",
    "        \n",
    "else:\n",
    "    print(\"⚠️  Skipping model training due to validation issues.\")\n",
    "    print(\"Focus on fixing data quality issues first.\")\n",
    "\n",
    "print(\"\\n🎉 PIPELINE EXECUTION COMPLETED!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
